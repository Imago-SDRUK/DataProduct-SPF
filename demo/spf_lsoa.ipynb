{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ade21dc",
   "metadata": {},
   "source": [
    "## **Cloud probability per LSOA**\n",
    "\n",
    "This Notebook explores ways to translate raster-calculated cloud probability per pixels to the polygon-based cloud probability. This ensures the data representation is understandable and much easier to implement into the regional and local policy-making.\n",
    "\n",
    "In this workflow we are using LSOA geographies from [here](https://github.com/Imago-SDRUK/geographies?tab=readme-ov-file#list-of-data) **(n=46844)**. The previous workflow provides output xarray Datasets exported to the tiled GeoTIFFs **(n=858)**. There are plenty of ways to calculate the LSOA-based stats [see here](https://gis.stackexchange.com/questions/481295/fastest-way-to-calculate-zonal-statistics-on-millions-of-small-polygons-and-stor), but we'll explore just a few:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5ac7c9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "from pystac_client import Client\n",
    "import geopandas as gpd\n",
    "import rioxarray\n",
    "from rioxarray import merge\n",
    "\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "\n",
    "from rasterstats import zonal_stats\n",
    "import xvec\n",
    "from exactextract import exact_extract\n",
    "\n",
    "import sys\n",
    "\n",
    "from dask.distributed import Client as DaskClient, LocalCluster\n",
    "from dask import delayed, compute\n",
    "\n",
    "import xvec\n",
    "print(xvec.__version__)\n",
    "sys.path.append('/src/external_libs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "085a3490-6862-4e54-9f4f-6f58313e2fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "lsoa=\"data/uk_datazones_within_newcastle.gpkg\"  # \"data/uk_datazones.gpkg\" if you want all LSOAs\n",
    "lsoa_id_col='LSOA21CD' # column name with unique LSOA IDs, as in `geographies`\n",
    "lsoa_gdf=gpd.read_file(lsoa) \n",
    "\n",
    "# output\n",
    "lsoa_stats_exactextract=\"data/lsoa_stats_exactextract.gpkg\"\n",
    "lsoa_stats_rasterstats=\"data/lsoa_stats_rasterstats.gpkg\"\n",
    "lsoa_stats_xvec_datasets=\"data/lsoa_stats_xvec_datasets.gpkg\"\n",
    "lsoa_stats_sjoin=\"data/lsoa_stats_sjoin.gpkg\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654fce44-f501-45be-a53c-98abc8e56518",
   "metadata": {},
   "source": [
    "In this code we run computations for the **data subset**:\n",
    "- six cloud probability datasets (Newcastle tiles)\n",
    "- all LSOAs entirely covered by the tiles (`within`). We don't include any LSOAs covering pixels in other tiles! In this case, we **replicate the real data relations** from the UK scale on the local scale -  all LSOAs are contained within tiles.\n",
    "\n",
    "For the sake of clarity, we open the previously exported GeoTIF cloud probability rasters as xarray Datasets. In the final version of workflow, this step can be omitted as **we don't need any intermediate exports**, taking up much resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b9b76a58-171e-4ca8-9e61-9c8bb295722b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully opened xarray Datasets\n"
     ]
    }
   ],
   "source": [
    "# Open input\n",
    "rasters = [\n",
    "    \"data/Newcastle_NZ26_2024.tif\",\n",
    "    \"data/Newcastle_NZ04_2024.tif\",\n",
    "    \"data/Newcastle_NZ24_2024.tif\",\n",
    "    \"data/Newcastle_NZ06_2024.tif\",\n",
    "    \"data/Newcastle_NZ44_2024.tif\",\n",
    "    \"data/Newcastle_NZ46_2024.tif\",\n",
    "]\n",
    "\n",
    "datasets = []\n",
    "for r in rasters:\n",
    "    ds = xr.open_dataset(r, engine=\"rasterio\")\n",
    "    datasets.append(ds)\n",
    "print(f\"Successfully opened xarray Datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46147d07",
   "metadata": {},
   "source": [
    "### 1. Zonal statistics\n",
    "Here, we utilise the classic`rasterstats.zonal_stats` tools to calculate statistics of cloud probability per LSOA.\n",
    "The output will create columns for each raster and band - it takes significant time to compute that (even without weighting mean values by the share of LSOA area in each raster tile)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "61ba589e-3819-4753-a7b5-7ea56e6a2a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed raster: data/Newcastle_NZ26_2024.tif\n",
      "Processed raster: data/Newcastle_NZ04_2024.tif\n",
      "Processed raster: data/Newcastle_NZ24_2024.tif\n",
      "Processed raster: data/Newcastle_NZ06_2024.tif\n",
      "Processed raster: data/Newcastle_NZ44_2024.tif\n",
      "Processed raster: data/Newcastle_NZ46_2024.tif\n",
      "Saved final LSOA stats to data/lsoa_stats_rasterstats.gpkg\n"
     ]
    }
   ],
   "source": [
    "all_stats=[]\n",
    "stats_list=['mean','median','min','max','std','count']\n",
    "\n",
    "# 1. Calculate stats for each raster (only first band)\n",
    "for raster in rasters:\n",
    "    zs = zonal_stats(\n",
    "        lsoa_gdf,\n",
    "        raster,\n",
    "        band=1, # only first band\n",
    "        stats=stats_list,\n",
    "        all_touched=True, # True or False without partial cell weighting\n",
    "        nodata=None,\n",
    "        geojson_out=False  # returns list of dictionaries\n",
    "    )\n",
    "\n",
    "    # 2. Convert to dataframe and add LSOA id\n",
    "    df = pd.DataFrame(zs)\n",
    "    df[lsoa_id_col] = lsoa_gdf[lsoa_id_col].values\n",
    "\n",
    "    # 3. Rename columns to include raster name\n",
    "    stat_cols = [col for col in df.columns if col != lsoa_id_col]\n",
    "    raster_name = raster.split('/')[-1].split('.')[0]  # extract raster filename\n",
    "    df.rename(columns={col: f\"{raster_name}_band_1_{col}\" for col in stat_cols}, inplace=True)\n",
    "\n",
    "    # 4. Append to list\n",
    "    all_stats.append(df)\n",
    "    print(f\"Processed raster: {raster}\")\n",
    "\n",
    "# 5. Set LSOA ID as index for each dataframe, concat side by side\n",
    "df_stats = pd.concat([df.set_index(lsoa_id_col) for df in all_stats], axis=1).reset_index()\n",
    "\n",
    "# 6. Merge with original geodataframe to retain geometries\n",
    "gdf_with_stats = lsoa_gdf.merge(df_stats, on=lsoa_id_col, how='left')\n",
    "\n",
    "# 7. convert and export\n",
    "gdf_with_stats = gpd.GeoDataFrame(gdf_with_stats, geometry='geometry', crs=lsoa_gdf.crs)\n",
    "gdf_with_stats.to_file(lsoa_stats_rasterstats, driver=\"GPKG\")\n",
    "print(f\"Saved final LSOA stats to {lsoa_stats_rasterstats}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a8e2cd-abb8-4e1f-bdc8-7953f4ff5db3",
   "metadata": {},
   "source": [
    "**Time**: 10s\n",
    "\n",
    "**Conclusion:**\n",
    "- can't accept xarray Dataset/Array - either opens GeoTIFF, or `rasterio` objects - **not recommended to use at all**\n",
    "- relatively slow (even without weighting)\n",
    "- extracts stats from all rasters even if they don't intersect (replacing values with 0). It requires additional processing and calculation by tile weight for each LSOA\n",
    "- no partial cell-weighting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d4a31d",
   "metadata": {},
   "source": [
    "### 2. `Exactextract`\n",
    "\n",
    "Library written in C++, perfectly working for single tiles (see Shaonlee's Notebook). Provides less custom statistics than `rasterstats`, but enough for our purposes.\n",
    "\n",
    "[Documentation here](https://isciences.github.io/exactextract/exactextract.html)\n",
    "\n",
    "The code below runs the calculations with weighting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "69a8fe50-624b-44ab-9568-758b42014c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved weighted aggregated LSOA statistics to data/lsoa_stats_exactextract.gpkg\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "stats = ['mean','min','max','count']\n",
    "\n",
    "# 1. extract stats for each dataset\n",
    "for ds in datasets:\n",
    "    stat_df = exact_extract(\n",
    "        rast=ds,\n",
    "        vec=lsoa_gdf,\n",
    "        ops=stats,\n",
    "        include_cols=[lsoa_id_col],\n",
    "        include_geom=True,\n",
    "        output='pandas',\n",
    "        strategy=\"feature-sequential\"\n",
    "    )\n",
    "    results.append(stat_df)\n",
    "    # NOTE: this will create a dataframe with columns like \"band_data_band_1_mean\"\n",
    "\n",
    "# 3. combine all results\n",
    "combined = pd.concat(results)\n",
    "\n",
    "# 4. identify statistic columns\n",
    "# since we only have one band, we just define its column names\n",
    "mean_col = \"band_data_band_1_mean\"\n",
    "min_col  = \"band_data_band_1_min\"\n",
    "max_col  = \"band_data_band_1_max\"\n",
    "count_col = \"band_data_band_1_count\"\n",
    "\n",
    "# 5. Pre-index geometries to avoid repeated access\n",
    "geom_map = lsoa_gdf.set_index(lsoa_id_col)['geometry'].to_dict()\n",
    "\n",
    "# 5. Compute weighted sum per row for weighted mean\n",
    "combined['weighted_sum'] = combined[mean_col] * combined[count_col]\n",
    "\n",
    "# 6. Aggregate by LSOA (vectorized)\n",
    "agg_df = combined.groupby(lsoa_id_col).agg(\n",
    "    weighted_sum=('weighted_sum', 'sum'),\n",
    "    total_count=(count_col, 'sum'),\n",
    "    min_val=(min_col, 'min'),\n",
    "    max_val=(max_col, 'max')\n",
    ").reset_index()\n",
    "\n",
    "# 7. Compute final weighted mean\n",
    "agg_df[mean_col] = agg_df['weighted_sum'] / agg_df['total_count']\n",
    "agg_df[count_col] = agg_df['total_count']\n",
    "agg_df = agg_df.drop(columns=['weighted_sum','total_count'])\n",
    "\n",
    "# 8. Add geometries using pre-indexed map\n",
    "agg_df['geometry'] = agg_df[lsoa_id_col].map(geom_map)\n",
    "\n",
    "# 9. convert and save\n",
    "out_gdf = gpd.GeoDataFrame(agg_df, geometry='geometry', crs=lsoa_gdf.crs)\n",
    "out_gdf.to_file(lsoa_stats_exactextract, driver=\"GPKG\")\n",
    "print(f\"Saved weighted aggregated LSOA statistics to {lsoa_stats_exactextract}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fa5987-6e85-4837-bf40-18e38e30738e",
   "metadata": {},
   "source": [
    "**Time**: 3s (with weighting)\n",
    "\n",
    "**Conclusion:**\n",
    "- fast, but nothing is clear about in-built parallelism\n",
    "- can be wrapped by Dask delayed\n",
    "- supports partial cell-weighting\n",
    "- considers LSOA coverage > 1 tile. To confirm, see values `band_data_band_2_mean` - this mean value of pixel value is not integer in LSOAs covering >1 tile (was integer in original dataset)\\\n",
    "- `exactextract` doesn't accept list of xarray Datasets as an input - only one, so we would have to loop over datasets, then aggregate results per LSOA\n",
    "- Requires C++ extensions installation, and might be not available through `pip`. Faces issues with the current image Python version (probably required <=3.11)\n",
    "- `exact_extract` can keep geometry and returns geodataframe in this case. You don't need to merge the output with the original dataframe - very efficient!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c897c255",
   "metadata": {},
   "source": [
    "#### 3. Xvec with Datasets\n",
    "\n",
    "`xvec` library can be used for creating a 'vector data cube' and calculating a zonal statistics.\n",
    "This method is similar to the classic zonal statistcs - keeping the structure of the original cube with attributes, but indexing by a polygon geometry. Here is the implementation of `xvec.zonal_stats` with Datasets. There is another option with `xvec.to_geodataframe` and spatial join after, but that one faced issues.\n",
    "\n",
    "[Documentation is here](https://xvec.readthedocs.io/en/stable/generated/xarray.Dataset.xvec.zonal_stats.html)\n",
    "\n",
    "Code below calculates average for each LSOA across tiles without weights. That could be implemented later though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1d16218d-8135-4c2d-b580-154d7ad95ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  zonal_statistics  band                                           geometry  \\\n",
      "0             mean     1  MULTIPOLYGON (((426698.655 562983.803, 426704....   \n",
      "1           median     1  MULTIPOLYGON (((426698.655 562983.803, 426704....   \n",
      "2              min     1  MULTIPOLYGON (((426698.655 562983.803, 426704....   \n",
      "3              max     1  MULTIPOLYGON (((426698.655 562983.803, 426704....   \n",
      "4            count     1  MULTIPOLYGON (((426698.655 562983.803, 426704....   \n",
      "5             mean     1  MULTIPOLYGON (((425968.068 562574.153, 425971....   \n",
      "6           median     1  MULTIPOLYGON (((425968.068 562574.153, 425971....   \n",
      "7              min     1  MULTIPOLYGON (((425968.068 562574.153, 425971....   \n",
      "8              max     1  MULTIPOLYGON (((425968.068 562574.153, 425971....   \n",
      "9            count     1  MULTIPOLYGON (((425968.068 562574.153, 425971....   \n",
      "\n",
      "   spatial_ref   LSOA21CD    band_data source_raster  \n",
      "0            0  E01008162    60.460705      raster_0  \n",
      "1            0  E01008162    60.397259      raster_0  \n",
      "2            0  E01008162    56.787670      raster_0  \n",
      "3            0  E01008162    65.678085      raster_0  \n",
      "4            0  E01008162  1209.000000      raster_0  \n",
      "5            0  E01008163    59.342606      raster_0  \n",
      "6            0  E01008163    59.345890      raster_0  \n",
      "7            0  E01008163    55.150684      raster_0  \n",
      "8            0  E01008163    64.376709      raster_0  \n",
      "9            0  E01008163   734.000000      raster_0  \n",
      "Saved final LSOA stats to data/lsoa_stats_xvec_datasets.gpkg\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "stats_list=['mean','median','min','max','count']\n",
    "\n",
    "# 1. Iterate over datasets to calculate stats, extracting single-band DataArray (first band only)\n",
    "for i, ds in enumerate(datasets):\n",
    "    raster_name = getattr(ds, \"name\", f\"raster_{i}\")\n",
    "\n",
    "    da = ds[\"band_data\"].isel(band=0).expand_dims(\"band\")  # use only the first band\n",
    "    #print(da)\n",
    "    #print(da.coords)\n",
    "    \n",
    "    stat_ds = da.xvec.zonal_stats(\n",
    "        geometry=lsoa_gdf[\"geometry\"],\n",
    "        x_coords=\"x\",\n",
    "        y_coords=\"y\",\n",
    "        stats=stats_list,\n",
    "        method=\"rasterize\"\n",
    "    )\n",
    "    \n",
    "    # 2. linking each geometry to its LSOA code and transform to geodataframe\n",
    "    stat_ds = stat_ds.assign_coords({lsoa_id_col: (\"geometry\", lsoa_gdf[lsoa_id_col].values)})\n",
    "    stat_ds.name = \"band_data\"\n",
    "    df = stat_ds.xvec.to_geodataframe(geometry=\"geometry\").reset_index()  # required to reset, otherwise `zonal_stats` will fly away to index\n",
    "    df[\"source_raster\"] = raster_name\n",
    "    df[\"band\"] = 1  # first band\n",
    "    \n",
    "    results.append(df)\n",
    "\n",
    "# 3. Combine all stats into one dataframe\n",
    "combined = pd.concat(results, ignore_index=True)\n",
    "print(combined.head(10))\n",
    "\n",
    "# 4. pivot table to multiindex format: rows = LSOA, columns = band + stat, values = band_data\n",
    "lsoa_stats_df = combined.pivot_table(\n",
    "    index=lsoa_id_col,\n",
    "    columns=['band', 'zonal_statistics'],  # multi-index columns\n",
    "    values='band_data',\n",
    "    aggfunc='mean'  # average across multiple occurrences\n",
    ")\n",
    "\n",
    "# 5. flatten multiindex columns: band_1_mean, band_1_max, etc.\n",
    "lsoa_stats_df.columns = [f\"band_{b}_{stat}\" for b, stat in lsoa_stats_df.columns]\n",
    "lsoa_stats_df = lsoa_stats_df.reset_index()\n",
    "\n",
    "# 6. convert and export\n",
    "lsoa_stats_df['geometry'] = combined.groupby(lsoa_id_col).geometry.first().values\n",
    "lsoa_stats_gdf = gpd.GeoDataFrame(lsoa_stats_df, geometry='geometry', crs=combined.crs)\n",
    "lsoa_stats_gdf.to_file(lsoa_stats_xvec_datasets, driver=\"GPKG\")\n",
    "print(f\"Saved final LSOA stats to {lsoa_stats_xvec_datasets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82abf97-b271-4107-832f-b91f3465a6af",
   "metadata": {},
   "source": [
    "**Time varies across methods**:\n",
    "\n",
    "- `exactextract` - 3s\n",
    "- `rasterize` - 3s (results identical to `exactextract`)\n",
    "- `iterate` - 29s\n",
    "\n",
    "**Conclusion:**\n",
    "- fast, but might be not clean (quirky - saves stats to the rows, not columns\n",
    "- newer versions work directly with xarray Datasets (not even Arrays), which is good\n",
    "- might conflict with the current container (currently using `xvec==0.4.0`). \n",
    "- `xvec.zonal_stats` is using `exactextract` under the hood (one of the methods)\n",
    "- as other methods, it cannot aggregate zonal stats for each LSOA across multiple rasters - you need to do it yourself the same as with `exactextract`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3349a7-2fe9-4364-8b19-4fa857975067",
   "metadata": {},
   "source": [
    "#### 4. Spatial join and `dask_geopandas`\n",
    "\n",
    "The idea is simple:\n",
    "- create a geodataframe from pixel centroids\n",
    "- perform spatial join between LSOA geodatagrame and cloud geodataframe\n",
    "- calculate zonal statistics\n",
    "\n",
    "Additionally, it's possible to use `dask_geopandas`. In this case geodataframes should be converted to Dask geodataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cadbe812-3a42-429d-978c-3d749e48525f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved final LSOA stats to data/lsoa_stats_sjoin.gpkg\n"
     ]
    }
   ],
   "source": [
    "# Try without Dask\n",
    "all_stats = []\n",
    "for i, ds in enumerate(datasets):\n",
    "    raster_name = f\"raster_{i}\"\n",
    "    da = ds[\"band_data\"]\n",
    "\n",
    "    # 1. convert to geodataframe\n",
    "    df = da.to_dataframe(name=\"value\").reset_index()\n",
    "    df[\"raster\"] = raster_name \n",
    "    # 2. make geodataframe\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df[\"x\"], df[\"y\"]), crs=\"EPSG:27700\")\n",
    "    # 3. spatial join\n",
    "    joined = gpd.sjoin(gdf, lsoa_gdf, how=\"inner\", predicate=\"intersects\")\n",
    "    # 4. calculate zonal stats per LSOA, per band, per raster\n",
    "    zonal_stats = joined.groupby([lsoa_id_col, \"band\", \"raster\"])[\"value\"].agg(\n",
    "        mean=\"mean\",\n",
    "        median=\"median\",\n",
    "        std=\"std\",\n",
    "        min=\"min\",\n",
    "        max=\"max\",\n",
    "        count=\"count\"\n",
    "    ).reset_index()\n",
    "\n",
    "    all_stats.append(zonal_stats)\n",
    "\n",
    "# 5. combine all raster stats into one dataframe\n",
    "all_stats_df = pd.concat(all_stats, ignore_index=True)\n",
    "\n",
    "# 6. merge with LSOA polygons without aggregating raster names\n",
    "lsoa_stats_gdf = lsoa_gdf.merge(all_stats_df, on=lsoa_id_col, how=\"inner\")\n",
    "\n",
    "# 7. convert to geodataframe and save\n",
    "lsoa_stats_gdf = gpd.GeoDataFrame(lsoa_stats_gdf, geometry=\"geometry\", crs=lsoa_gdf.crs)\n",
    "lsoa_stats_gdf.to_file(lsoa_stats_sjoin, driver=\"GPKG\")\n",
    "print(f\"Saved final LSOA stats to {lsoa_stats_sjoin}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e92acf-3f34-4172-aeac-99b39fd36f78",
   "metadata": {},
   "source": [
    "**Time:** 10s for non-Dasked version\n",
    "\n",
    "**Conclusion**:\n",
    "- not fast without Dask\n",
    "- Dask fails as refers to `geopandas` instead of `dask_geopandas` which requires GeoDataFrame, while our objects are Dask-backed\n",
    "- can ingest `chunks_size` argument from the cloud probability raster workflow\n",
    "- Output partitions are the intersection of left and right geodataframes. When passing `chunks_size`, it's recommended to use partitions for the left deodataframe only. Otherwise chunks number may become excessively large.\n",
    "- only includes pixels whose centroids are within LSOAs\n",
    "- Dask doesn't work with operations like `merge`\n",
    "\n",
    "`dask-geopandas` is experimental (eg, only `inner` join is supported), so could require maintenance. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
