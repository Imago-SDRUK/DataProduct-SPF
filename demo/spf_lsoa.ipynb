{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ade21dc",
   "metadata": {},
   "source": [
    "### **Cloud probability per LSOA**\n",
    "\n",
    "This Notebook explores ways to translate raster-calculated cloud probability per pixels to the polygon-based cloud probability. This ensures the data representation is understandable and much easier to implement into the regional and local policy-making.\n",
    "\n",
    "In this workflow we are using LSOA geographies from [here](https://github.com/Imago-SDRUK/geographies?tab=readme-ov-file#list-of-data) (n=46844). The previous workflow provides output xarray Datasets exported to the tiled GeoTIFFs (n=858)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "5ac7c9cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cloud_mean_bbox=rasterio.open(\"Newcastle_NZ26_2024.tif\") # TODO - open through load_tile()\\ncloud_mean_bbox_xr = rioxarray.open_rasterio(cloud_mean_bbox, mask_and_scale=False)\\ncloud_mean = rioxarray.open_rasterio(\"data/Newcastle_NZ26_2024.tif\")'"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "# Define a replacement, minimal AlignmentError\n",
    "class AlignmentError(ValueError):\n",
    "    \"\"\"Compatibility shim for xarray.AlignmentError removed in xarray >= 2025.\"\"\"\n",
    "    pass\n",
    "\n",
    "# Patch it into xarray so xvec/xproj can import it\n",
    "xr.AlignmentError = AlignmentError\n",
    "\n",
    "\n",
    "from pystac_client import Client\n",
    "import geopandas as gpd\n",
    "import rioxarray\n",
    "from rioxarray import merge\n",
    "\n",
    "import odc.stac\n",
    "\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "\n",
    "import yaml\n",
    "import warnings\n",
    "\n",
    "from rasterstats import zonal_stats\n",
    "import xvec\n",
    "from exactextract import exact_extract\n",
    "\n",
    "import tempfile\n",
    "\n",
    "import rasterio\n",
    "\n",
    "import sys\n",
    "\n",
    "from dask.distributed import Client as DaskClient, LocalCluster\n",
    "from dask import delayed, compute\n",
    "\n",
    "sys.path.append('/src/external_libs')\n",
    "#os.environ[\"PROJ_LIB\"] = pyproj.datadir.get_data_dir()\n",
    "\n",
    "lsoa=\"data/uk_datazones_within_newcastle.gpkg\"  # \"data/uk_datazones.gpkg\" if you want all LSOAs\n",
    "tiles=\"data/uk_20km_grid_Newcastle_subset.gpkg\" # \"data/uk_20km_grid.gpkg\" for all tiles\n",
    "lsoa_id_col='LSOA21CD' # column name with unique LSOA IDs, as in `geographies`\n",
    "\n",
    "# output stats\n",
    "lsoa_stats_exactextract=\"data/lsoa_stats_exactextract.gpkg\"\n",
    "lsoa_stats_rasterstats=\"data/lsoa_stats_rasterstats.gpkg\"\n",
    "lsoa_stats_xvec=\"data/lsoa_stats_xvec.gpkg\"\n",
    "\n",
    "#lsoa_stats_tile_path=\"data/lsoa_tile.gpkg\"\n",
    "# soa_intersected_path=\"data/lsoa_tile_intersected.gpkg\"\n",
    "\n",
    "lsoa_gdf=gpd.read_file(lsoa)\n",
    "tiles=gpd.read_file(tiles)\n",
    "tile=tiles.iloc[[3]].copy()\n",
    "\n",
    "#reload cloud probability product\n",
    "\"\"\"cloud_mean_bbox=rasterio.open(\"Newcastle_NZ26_2024.tif\") # TODO - open through load_tile()\n",
    "cloud_mean_bbox_xr = rioxarray.open_rasterio(cloud_mean_bbox, mask_and_scale=False)\n",
    "cloud_mean = rioxarray.open_rasterio(\"data/Newcastle_NZ26_2024.tif\")\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654fce44-f501-45be-a53c-98abc8e56518",
   "metadata": {},
   "source": [
    "In this code we run computations for the **data subset**:\n",
    "- six cloud probability datasets (Newcastle tiles)\n",
    "- all LSOAs entirely covered by the tiles (`within`). We don't include any LSOAs covering pixels from other tiles! In this case, we **replicate the real data relations** from the UK scale on the local scale - all LSOAs in the UK are covered by cloud probability datasets (none of them is outside).\n",
    "\n",
    "For the sake of clarity, we open the previously exported GeoTIF cloud probability rasters as xarray Datasets. In the final version of workflow, this step can be omitted as **we don't need any intermediate exports**, taking up much resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "b9b76a58-171e-4ca8-9e61-9c8bb295722b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "from typing import Sequence\n",
    "\n",
    "def open_cloud_datasets(*paths: str | Path) -> list[xr.Dataset]:\n",
    "    datasets = []\n",
    "    for i, p in enumerate(paths, 1):\n",
    "        ds = xr.open_dataset(p, engine=\"rasterio\")\n",
    "        if ds.rio.crs is None:\n",
    "            ds = ds.rio.write_crs(ds.rio.read_crs() or \"EPSG:27700\")\n",
    "        datasets.append(ds)\n",
    "\n",
    "    print(f\"Successfully opened {len(datasets)} xarray Datasets\")\n",
    "\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "0d32a7e8-3dda-41d3-9e25-4a7d631dee43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully opened 6 xarray Datasets\n",
      "[<xarray.Dataset> Size: 8MB\n",
      "Dimensions:      (band: 2, x: 1000, y: 1000)\n",
      "Coordinates:\n",
      "  * band         (band) int64 16B 1 2\n",
      "  * x            (x) float64 8kB 4.2e+05 4.2e+05 4.2e+05 ... 4.4e+05 4.4e+05\n",
      "  * y            (y) float64 8kB 5.8e+05 5.8e+05 5.8e+05 ... 5.6e+05 5.6e+05\n",
      "    spatial_ref  int64 8B ...\n",
      "Data variables:\n",
      "    band_data    (band, y, x) float32 8MB ..., <xarray.Dataset> Size: 8MB\n",
      "Dimensions:      (band: 2, x: 1000, y: 1000)\n",
      "Coordinates:\n",
      "  * band         (band) int64 16B 1 2\n",
      "  * x            (x) float64 8kB 4e+05 4e+05 4e+05 ... 4.2e+05 4.2e+05 4.2e+05\n",
      "  * y            (y) float64 8kB 5.6e+05 5.6e+05 5.6e+05 ... 5.4e+05 5.4e+05\n",
      "    spatial_ref  int64 8B ...\n",
      "Data variables:\n",
      "    band_data    (band, y, x) float32 8MB ..., <xarray.Dataset> Size: 8MB\n",
      "Dimensions:      (band: 2, x: 1000, y: 1000)\n",
      "Coordinates:\n",
      "  * band         (band) int64 16B 1 2\n",
      "  * x            (x) float64 8kB 4.2e+05 4.2e+05 4.2e+05 ... 4.4e+05 4.4e+05\n",
      "  * y            (y) float64 8kB 5.6e+05 5.6e+05 5.6e+05 ... 5.4e+05 5.4e+05\n",
      "    spatial_ref  int64 8B ...\n",
      "Data variables:\n",
      "    band_data    (band, y, x) float32 8MB ..., <xarray.Dataset> Size: 8MB\n",
      "Dimensions:      (band: 2, x: 1000, y: 1000)\n",
      "Coordinates:\n",
      "  * band         (band) int64 16B 1 2\n",
      "  * x            (x) float64 8kB 4e+05 4e+05 4e+05 ... 4.2e+05 4.2e+05 4.2e+05\n",
      "  * y            (y) float64 8kB 5.8e+05 5.8e+05 5.8e+05 ... 5.6e+05 5.6e+05\n",
      "    spatial_ref  int64 8B ...\n",
      "Data variables:\n",
      "    band_data    (band, y, x) float32 8MB ..., <xarray.Dataset> Size: 8MB\n",
      "Dimensions:      (band: 2, x: 1000, y: 1000)\n",
      "Coordinates:\n",
      "  * band         (band) int64 16B 1 2\n",
      "  * x            (x) float64 8kB 4.4e+05 4.4e+05 4.4e+05 ... 4.6e+05 4.6e+05\n",
      "  * y            (y) float64 8kB 5.6e+05 5.6e+05 5.6e+05 ... 5.4e+05 5.4e+05\n",
      "    spatial_ref  int64 8B ...\n",
      "Data variables:\n",
      "    band_data    (band, y, x) float32 8MB ..., <xarray.Dataset> Size: 8MB\n",
      "Dimensions:      (band: 2, x: 1000, y: 1000)\n",
      "Coordinates:\n",
      "  * band         (band) int64 16B 1 2\n",
      "  * x            (x) float64 8kB 4.4e+05 4.4e+05 4.4e+05 ... 4.6e+05 4.6e+05\n",
      "  * y            (y) float64 8kB 5.8e+05 5.8e+05 5.8e+05 ... 5.6e+05 5.6e+05\n",
      "    spatial_ref  int64 8B ...\n",
      "Data variables:\n",
      "    band_data    (band, y, x) float32 8MB ...]\n"
     ]
    }
   ],
   "source": [
    "rasters = [\n",
    "    \"data/Newcastle_NZ26_2024.tif\",\n",
    "    \"data/Newcastle_NZ04_2024.tif\",\n",
    "    \"data/Newcastle_NZ24_2024.tif\",\n",
    "    \"data/Newcastle_NZ06_2024.tif\",\n",
    "    \"data/Newcastle_NZ44_2024.tif\",\n",
    "    \"data/Newcastle_NZ46_2024.tif\",\n",
    "]\n",
    "\n",
    "datasets = open_cloud_datasets(*rasters)\n",
    "\n",
    "print(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d4a31d",
   "metadata": {},
   "source": [
    "#### 1. `Exactextract`\n",
    "\n",
    "**Pros:**\n",
    "* Written in C++, fast\n",
    "* Partial cell-weighting.\n",
    "\n",
    "**Cons:**\n",
    "* `exactextract` doesn't accept list of xarray Datasets as an input - only one, so we would have to loop over\n",
    "* raster I/O is not chunk-aware - parallelism is possible, but it will read through all chunks...?\n",
    "* Few custom statistics.\n",
    "* Requires C++ extensions installation, and might be not available through `pip`. Faces issues with the current image Python version (probably required <=3.11)\n",
    "\n",
    "The following worked:\n",
    "- `conda install -c conda-forge cmake compilers`\n",
    "- `conda install -c conda-forge exactextract`\n",
    "\n",
    "As we can't feed in the list of datasets, we would need to loop over datasets and then combine and aggregate results by the LSOA ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "69a8fe50-624b-44ab-9568-758b42014c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def calc_lsoa_stats_exactextract(datasets, lsoa_gdf, out_file, lsoa_id_col='LSOA21CD'):\n",
    "    \"\"\"\n",
    "    Calculate zonal statistics for multiple xarray datasets over LSOA polygons, weighted by the number of pixels in LSOA covered by each tile\n",
    "\n",
    "    Outputs are identical.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    datasets : list of xarray.DataArray or xarray.Dataset\n",
    "        The raster datasets to extract from.\n",
    "    lsoa_gdf : geopandas.GeoDataFrame\n",
    "        Polygons over which to calculate statistics.\n",
    "    lsoa_id_col : str\n",
    "        Name of the column in lsoa_gdf with unique polygon IDs.\n",
    "    stats : list of str\n",
    "        List of statistics to calculate (mean, median, min, max, stdev, count).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Aggregated statistics per LSOA ID.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    stats = ['mean','min','max','count']\n",
    "\n",
    "    # extract stats for each dataset\n",
    "    for ds in datasets:\n",
    "        stat_df = exact_extract(\n",
    "            rast=ds,\n",
    "            vec=lsoa_gdf,\n",
    "            ops=stats,\n",
    "            include_cols=[lsoa_id_col],\n",
    "            include_geom=True,\n",
    "            output='pandas'\n",
    "            #strategy=\"raster-sequential\" # TODO - to test this instead of default \"feature-sequential\"\n",
    "            #weights=... # this shouldn't be used in this case unless we want to weight the cloud probability by the pixel count from the processed dataset (band 2)\n",
    "        )\n",
    "        results.append(stat_df)\n",
    "\n",
    "        # NOTE: this will create a dataframe with columns of the following pattern: \"band_data_band_<num>_<stat>\", eg \"band_data_band_1_mean\"\n",
    "        #print(stat_df.columns)\n",
    "        #stat_df.head()\n",
    "\n",
    "    combined = pd.concat(results)\n",
    "\n",
    "    # Extract unique band prefixes (everything before _mean/_min/_max/_count)\n",
    "    suffixes = ['_mean', '_min', '_max', '_count']\n",
    "    pattern = r\"(.*)_(mean|min|max|count)\"\n",
    "\n",
    "    stat_cols = [c for c in combined.columns if any(c.endswith(s) for s in suffixes)] # we need to extract names of columns with stats\n",
    "    band_prefixes = sorted({re.match(pattern, c).group(1) for c in stat_cols})\n",
    "\n",
    "    grouped = combined.groupby(lsoa_id_col) # group rows by LSOA ID\n",
    "    output_rows = []\n",
    "\n",
    "    # aggregate per LSOA polygon\n",
    "    for lsoa, group in grouped:\n",
    "        # start row with geometry from the first occurrence\n",
    "        row = {lsoa_id_col: lsoa, 'geometry': group.iloc[0].geometry} #take the geometry from the first row - they are the same\n",
    "\n",
    "        for band in band_prefixes:\n",
    "            mean_col = f\"{band}_mean\"\n",
    "            min_col  = f\"{band}_min\"\n",
    "            max_col  = f\"{band}_max\"\n",
    "            count_col = f\"{band}_count\"\n",
    "\n",
    "            if mean_col not in group:\n",
    "                continue\n",
    "\n",
    "            # WEIGHTING\n",
    "            num = (group[mean_col] * group[count_col]).sum() #multiply mean value for that band in ONE raster by number of pixels contributing to that mean and then SUM\n",
    "            total = group[count_col].sum() #SUM of pixel numbers contributing to the mean\n",
    "            wmean = num / total if total > 0 else None # final weighted mean across all rasters\n",
    "\n",
    "            # add to row\n",
    "            row[f\"{band}_mean\"] = wmean \n",
    "            row[f\"{band}_min\"] = group[min_col].min()\n",
    "            row[f\"{band}_max\"] = group[max_col].max()\n",
    "            row[f\"{band}_count\"] = total\n",
    "\n",
    "        output_rows.append(row)\n",
    "\n",
    "    out_gdf = pd.DataFrame(output_rows) # conver the list of dictionaries into a geodataframe, so each row is a LSOA polygon with aggregated and weighted\n",
    "    out_gdf = out_gdf.set_geometry('geometry')\n",
    "    out_gdf.crs=lsoa_gdf.crs\n",
    "\n",
    "    \"\"\"#DEPRECATED - merge with original polygons\n",
    "    #lsoa_with_stats = lsoa_gdf.merge(out_df, on=lsoa_id_col, how='left')\"\"\"\n",
    "    out_gdf.to_file(out_file, driver=\"GPKG\")\n",
    "\n",
    "    print(f\"Saved weighted aggregated LSOA statistics to {out_file}\")\n",
    "\n",
    "    return out_gdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "3a69a6a9-c92e-46d2-92c0-708446aac631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved weighted aggregated LSOA statistics to data/lsoa_stats_exactextract.gpkg\n",
      "      LSOA21CD                                           geometry  \\\n",
      "0    E01008162  MULTIPOLYGON (((426698.655 562983.803, 426704....   \n",
      "1    E01008163  MULTIPOLYGON (((425968.068 562574.153, 425971....   \n",
      "2    E01008164  MULTIPOLYGON (((426690.327 562513.51, 426597 5...   \n",
      "3    E01008165  MULTIPOLYGON (((426095 562463, 426145 562292, ...   \n",
      "4    E01008166  MULTIPOLYGON (((427011.334 563237.222, 426841....   \n",
      "..         ...                                                ...   \n",
      "941  E01035625  MULTIPOLYGON (((429975.663 573394.466, 430543....   \n",
      "942  E01035626  MULTIPOLYGON (((431383.313 573499.812, 431486....   \n",
      "943  E01035627  MULTIPOLYGON (((430305.059 570535.324, 430373....   \n",
      "944  E01035628  MULTIPOLYGON (((430565.719 570620.231, 430815....   \n",
      "945  E01035636  MULTIPOLYGON (((409032.084 562824.327, 409105....   \n",
      "\n",
      "     band_data_band_1_mean  band_data_band_1_min  band_data_band_1_max  \\\n",
      "0                60.461379             56.684933             65.678085   \n",
      "1                59.347308             55.150684             64.376709   \n",
      "2                61.965570             57.958904             69.287674   \n",
      "3                60.870251             57.650684             64.164383   \n",
      "4                60.188016             54.164383             69.041100   \n",
      "..                     ...                   ...                   ...   \n",
      "941              55.208045             48.438354             62.684933   \n",
      "942              52.463574             44.452053             60.356163   \n",
      "943              57.594987             51.219177             67.404106   \n",
      "944              58.166762             50.136986             65.390411   \n",
      "945              62.950292             59.365517             66.662071   \n",
      "\n",
      "     band_data_band_1_count  band_data_band_2_mean  band_data_band_2_min  \\\n",
      "0               1208.550662             146.000000                 146.0   \n",
      "1                738.083929             146.000000                 146.0   \n",
      "2                560.414216             145.268947                  73.0   \n",
      "3                788.458873             143.371092                  73.0   \n",
      "4               3572.897086             146.000000                 146.0   \n",
      "..                      ...                    ...                   ...   \n",
      "941             8792.080306              75.971516                  73.0   \n",
      "942             5247.302328              74.692223                  73.0   \n",
      "943             1242.891656             146.000000                 146.0   \n",
      "944             3908.018329             146.000000                 146.0   \n",
      "945             1664.960825             264.916482                 145.0   \n",
      "\n",
      "     band_data_band_2_max  band_data_band_2_count  \n",
      "0                   146.0             1208.550662  \n",
      "1                   146.0              738.083929  \n",
      "2                   146.0              560.414216  \n",
      "3                   146.0              788.458873  \n",
      "4                   146.0             3572.897086  \n",
      "..                    ...                     ...  \n",
      "941                 146.0             8792.080306  \n",
      "942                 146.0             5247.302328  \n",
      "943                 146.0             1242.891656  \n",
      "944                 146.0             3908.018329  \n",
      "945                 290.0             1664.960825  \n",
      "\n",
      "[946 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "lsoa_with_stats=calc_lsoa_stats_exactextract(\n",
    "    datasets=datasets,\n",
    "    lsoa_gdf=lsoa_gdf,\n",
    "    lsoa_id_col=lsoa_id_col,\n",
    "    out_file=lsoa_stats_exactextract\n",
    ")\n",
    "\n",
    "print(lsoa_with_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fa5987-6e85-4837-bf40-18e38e30738e",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "- quick, but not Dask-aware - `concat` calculates everything?\n",
    "- considers LSOA coverage > 1 tile (proven by `band_data_band_2_mean` which is not always integer)\n",
    "- There are two ways to work with geometries in `exact_extract`. They give the identical outputs, but differ in resource involved:\n",
    "    1. [**recommended, implemented**] define `include_geom=True` so the `exact_extract` returns geodataframe. Then define geometry from each LSOA group by raster as the first geometry (they are all the same).\n",
    "    2. do not define `include_geom`, so the `exact_extract` returns dataframe. Then merge the original dataframe with stats on the LSOA on 'lsoa_id' (left join)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46147d07",
   "metadata": {},
   "source": [
    "#### 2. Zonal statistics\n",
    "Here, we utilise `rasterstats.zonal_stats` to calculate statistics of cloud probability per LSOA:\n",
    "\n",
    "**Pros**:\n",
    "* Classic tool, widely supported\n",
    "* Allows custom statistics.\n",
    "\n",
    "**Cons**:\n",
    "* Could be wrapped in Dask.delayed, but raster is read through a non-parallelised rasterio driver\n",
    "* Not able to weight the raster cells intersecting polygon boundaries by their partial overlap.\n",
    "* Slower (Python + numpy)\n",
    "* Could be memory-heavy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ba589e-3819-4753-a7b5-7ea56e6a2a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def calc_lsoa_stats_rasterstats(rasters, lsoa_gdf, out_file, lsoa_id_col='LSOA21CD'):\n",
    "    \"\"\"\n",
    "    Calculate zonal statistics for multiple raster datasets over LSOA polygons using rasterstats.zonal_stats.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rasters : list of str or rasterio.DatasetReader\n",
    "        Raster files or opened raster objects.\n",
    "    lsoa_gdf : geopandas.GeoDataFrame\n",
    "        Polygons over which to calculate statistics.\n",
    "    out_file : str\n",
    "        Path to save GeoPackage with merged stats.\n",
    "    lsoa_id_col : str\n",
    "        Column name of unique polygon IDs.\n",
    "    stats : list of str\n",
    "        Statistics to calculate ('mean','median','min','max','std','count').\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Aggregated statistics per LSOA ID.\n",
    "    \"\"\"\n",
    "    all_stats = []\n",
    "\n",
    "    for raster in rasters:\n",
    "        # Compute stats directly\n",
    "        zs = zonal_stats(\n",
    "            lsoa_gdf,\n",
    "            raster,\n",
    "            stats=['mean','median','min','max','std','count'],\n",
    "            all_touched=True,  # include all pixels touched by polygon\n",
    "            nodata=None,       # let rasterstats handle nodata properly\n",
    "            geojson_out=False\n",
    "        )\n",
    "\n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame(zs)\n",
    "        df[lsoa_id_col] = lsoa_gdf[lsoa_id_col].values  # add LSOA IDs\n",
    "\n",
    "        # Optional: prefix columns by raster filename to avoid collisions\n",
    "        raster_name = raster.split('/')[-1].split('.')[0]\n",
    "        df = df.rename(columns={stat: f\"{raster_name}_{stat}\" for stat in ['mean','median','min','max','std','count']})\n",
    "\n",
    "        all_stats.append(df)\n",
    "\n",
    "    # Merge stats from all rasters\n",
    "    df_stats = all_stats[0]\n",
    "    for df in all_stats[1:]:\n",
    "        df_stats = df_stats.merge(df, on=lsoa_id_col, how='left')\n",
    "\n",
    "    # Merge with original GeoDataFrame\n",
    "    gdf_with_stats = lsoa_gdf.merge(df_stats, on=lsoa_id_col, how='left')\n",
    "\n",
    "    # Save to GeoPackage\n",
    "    gdf_with_stats.to_file(out_file, driver=\"GPKG\")\n",
    "    print(f\"Saved final LSOA stats to {out_file}\")\n",
    "    \n",
    "    return df_stats, gdf_with_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c21ccc-b82b-4c56-883f-e38f1af68e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsoa_stats, lsoa_gdf_with_stats = calc_lsoa_stats_rasterstats(\n",
    "    rasters=rasters,\n",
    "    lsoa_gdf=lsoa_gdf,\n",
    "    out_file=lsoa_stats_rasterstats,\n",
    "    lsoa_id_col=lsoa_id_col\n",
    ")\n",
    "\n",
    "print(lsoa_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a8e2cd-abb8-4e1f-bdc8-7953f4ff5db3",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "- can't accept xarray Dataset/Array - either opens GeoTIFF, or `rasterio` objects - **not recommended to use at all**\n",
    "- extracts stats from all rasters even if they don't intersect (replacing with 0), which requires additional processing and calculation by tile weight for each LSOA\n",
    "- slower and not Dask-aware - `concat` calculates everything"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c897c255",
   "metadata": {},
   "source": [
    "#### 3.1. Xvec zonal stats\n",
    "\n",
    "`xvec` library can be used for creating a 'vector data cube' and calculating a zonal statistics.\n",
    "This method is similar to the classic zonal statistcs - keeping the structure of the original cube with attributes, but indexing by a polygon geometry.\n",
    "The main question - how better does it perform compared to other methods if using Dask and HPC?\n",
    "\n",
    "Here is the implementation of `xvec.zonal_stats`, but there could be another option - `xvec.to_geodataframe` with pixel value extraction + spatial joins between cloud geodataframe and LSOA geodataframe.Here is the implementation of `xvec.zonal_stats`, but there could be another option - `xvec.to_geodataframe` with pixel value extraction + spatial joins between cloud geodataframe and LSOA geodataframe.\n",
    "\n",
    "See documentation [here](https://xvec.readthedocs.io/en/stable/zonal_stats.html) for further detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "1d16218d-8135-4c2d-b580-154d7ad95ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_lsoa_stats_xvec(datasets, lsoa_gdf, out_file, lsoa_id_col=\"LSOA21CD\", band_index=0):\n",
    "    \"\"\"\n",
    "    Compute zonal statistics using xvec.zonal_stats for speed.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    stats_list=[\"mean\", \"sum\", \"min\", \"max\"]\n",
    "\n",
    "    for i, ds in enumerate(datasets):\n",
    "\n",
    "        #print(lsoa_gdf.head())\n",
    "        #print(ds)\n",
    "\n",
    "        da = ds[\"band_data\"].isel(band=band_index)\n",
    "        stat_ds = da.xvec.zonal_stats(\n",
    "            geometry=lsoa_gdf[\"geometry\"],\n",
    "            x_coords=\"x\",\n",
    "            y_coords=\"y\",\n",
    "            stats=stats_list\n",
    "            #method=\"exactextract\" DEFAULT\n",
    "        )\n",
    "\n",
    "        \n",
    "        # NOTE: this creates a dataarray with two dimensions:\n",
    "        # `geometry` - basically LSOA\n",
    "        # `zonal_statistics` - headers with stat names\n",
    "        # coordinates transformed to `GeometryIndex`\n",
    "\n",
    "        # Add LSOA IDs as a coordinate\n",
    "        stat_ds = stat_ds.assign_coords({lsoa_id_col: (\"geometry\", lsoa_gdf[lsoa_id_col].values)})\n",
    "        # print(stat_ds.head(30))\n",
    "\n",
    "        # Convert to GeoDataFrame\n",
    "        df= stat_ds.xvec.to_geodataframe().reset_index()\n",
    "        #print(df.columns)\n",
    "        stat_df = df.pivot(index=\"geometry\", columns=\"zonal_statistics\", values=\"band_data\").reset_index()\n",
    "        # TODO - LSOA id column is lost when pivoting\n",
    "\n",
    "        # add raster source\n",
    "        stat_df[\"source_raster\"] = getattr(ds, \"name\", f\"raster_{i}\")\n",
    "\n",
    "        results.append(stat_df)\n",
    "\n",
    "        print(stat_df.head())\n",
    "\n",
    "    \n",
    "    # combine all datasets\n",
    "    combined = pd.concat(results, ignore_index=True)\n",
    "    print(combined.columns)\n",
    "\n",
    "    # aggregate per LSOA\n",
    "    lsoa_stats = combined.groupby(lsoa_id_col)[stats_list].agg(\"mean\").reset_index()\n",
    "\n",
    "    # merge back with original polygons\n",
    "    lsoa_gdf_with_stats = lsoa_gdf.merge(lsoa_stats, on=lsoa_id_col, how=\"left\")\n",
    "\n",
    "    lsoa_gdf_with_stats.to_file(out_file, driver=\"GPKG\", layer=\"lsoa_stats\")\n",
    "    print(f\"Saved LSOA statistics to {out_file}\")\n",
    "\n",
    "    return lsoa_gdf_with_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "c1f0d9bc-cf45-4a25-961c-0eb6c01b4a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zonal_statistics                                           geometry  max  \\\n",
      "0                 MULTIPOLYGON (((408824.904 550047.415, 408890 ...  NaN   \n",
      "1                 MULTIPOLYGON (((410011.459 550191.508, 410063....  NaN   \n",
      "2                 MULTIPOLYGON (((412368.453 549984.768, 412208 ...  NaN   \n",
      "3                 MULTIPOLYGON (((412648.063 549799.562, 412885....  NaN   \n",
      "4                 MULTIPOLYGON (((415704.375 550617.312, 415795....  NaN   \n",
      "\n",
      "zonal_statistics  mean  min  sum source_raster  \n",
      "0                  NaN  NaN  NaN      raster_0  \n",
      "1                  NaN  NaN  NaN      raster_0  \n",
      "2                  NaN  NaN  NaN      raster_0  \n",
      "3                  NaN  NaN  NaN      raster_0  \n",
      "4                  NaN  NaN  NaN      raster_0  \n",
      "zonal_statistics                                           geometry  \\\n",
      "0                 MULTIPOLYGON (((408824.904 550047.415, 408890 ...   \n",
      "1                 MULTIPOLYGON (((410011.459 550191.508, 410063....   \n",
      "2                 MULTIPOLYGON (((412368.453 549984.768, 412208 ...   \n",
      "3                 MULTIPOLYGON (((412648.063 549799.562, 412885....   \n",
      "4                 MULTIPOLYGON (((415704.375 550617.312, 415795....   \n",
      "\n",
      "zonal_statistics        max       mean        min           sum source_raster  \n",
      "0                 63.275864  56.587410  52.972412  2.268021e+05      raster_1  \n",
      "1                 68.172417  59.338638  52.875862  2.492223e+05      raster_1  \n",
      "2                 67.937927  57.801342  53.834484  1.095913e+05      raster_1  \n",
      "3                 74.635040  60.597466  55.503498  1.778535e+05      raster_1  \n",
      "4                 66.885963  56.122566  42.328766  6.467456e+06      raster_1  \n",
      "zonal_statistics                                           geometry  \\\n",
      "0                 MULTIPOLYGON (((408824.904 550047.415, 408890 ...   \n",
      "1                 MULTIPOLYGON (((410011.459 550191.508, 410063....   \n",
      "2                 MULTIPOLYGON (((412368.453 549984.768, 412208 ...   \n",
      "3                 MULTIPOLYGON (((412648.063 549799.562, 412885....   \n",
      "4                 MULTIPOLYGON (((415704.375 550617.312, 415795....   \n",
      "\n",
      "zonal_statistics        max       mean        min         sum source_raster  \n",
      "0                       NaN        NaN        NaN         NaN      raster_2  \n",
      "1                       NaN        NaN        NaN         NaN      raster_2  \n",
      "2                       NaN        NaN        NaN         NaN      raster_2  \n",
      "3                       NaN        NaN        NaN         NaN      raster_2  \n",
      "4                 58.273972  55.715069  53.054794  557.150696      raster_2  \n",
      "zonal_statistics                                           geometry  max  \\\n",
      "0                 MULTIPOLYGON (((408824.904 550047.415, 408890 ...  NaN   \n",
      "1                 MULTIPOLYGON (((410011.459 550191.508, 410063....  NaN   \n",
      "2                 MULTIPOLYGON (((412368.453 549984.768, 412208 ...  NaN   \n",
      "3                 MULTIPOLYGON (((412648.063 549799.562, 412885....  NaN   \n",
      "4                 MULTIPOLYGON (((415704.375 550617.312, 415795....  NaN   \n",
      "\n",
      "zonal_statistics  mean  min  sum source_raster  \n",
      "0                  NaN  NaN  NaN      raster_3  \n",
      "1                  NaN  NaN  NaN      raster_3  \n",
      "2                  NaN  NaN  NaN      raster_3  \n",
      "3                  NaN  NaN  NaN      raster_3  \n",
      "4                  NaN  NaN  NaN      raster_3  \n",
      "zonal_statistics                                           geometry  max  \\\n",
      "0                 MULTIPOLYGON (((408824.904 550047.415, 408890 ...  NaN   \n",
      "1                 MULTIPOLYGON (((410011.459 550191.508, 410063....  NaN   \n",
      "2                 MULTIPOLYGON (((412368.453 549984.768, 412208 ...  NaN   \n",
      "3                 MULTIPOLYGON (((412648.063 549799.562, 412885....  NaN   \n",
      "4                 MULTIPOLYGON (((415704.375 550617.312, 415795....  NaN   \n",
      "\n",
      "zonal_statistics  mean  min  sum source_raster  \n",
      "0                  NaN  NaN  NaN      raster_4  \n",
      "1                  NaN  NaN  NaN      raster_4  \n",
      "2                  NaN  NaN  NaN      raster_4  \n",
      "3                  NaN  NaN  NaN      raster_4  \n",
      "4                  NaN  NaN  NaN      raster_4  \n",
      "zonal_statistics                                           geometry  max  \\\n",
      "0                 MULTIPOLYGON (((408824.904 550047.415, 408890 ...  NaN   \n",
      "1                 MULTIPOLYGON (((410011.459 550191.508, 410063....  NaN   \n",
      "2                 MULTIPOLYGON (((412368.453 549984.768, 412208 ...  NaN   \n",
      "3                 MULTIPOLYGON (((412648.063 549799.562, 412885....  NaN   \n",
      "4                 MULTIPOLYGON (((415704.375 550617.312, 415795....  NaN   \n",
      "\n",
      "zonal_statistics  mean  min  sum source_raster  \n",
      "0                  NaN  NaN  NaN      raster_5  \n",
      "1                  NaN  NaN  NaN      raster_5  \n",
      "2                  NaN  NaN  NaN      raster_5  \n",
      "3                  NaN  NaN  NaN      raster_5  \n",
      "4                  NaN  NaN  NaN      raster_5  \n",
      "Index(['geometry', 'max', 'mean', 'min', 'sum', 'source_raster'], dtype='object', name='zonal_statistics')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'LSOA21CD'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[179], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m lsoa_stats \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_lsoa_stats_xvec\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlsoa_gdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlsoa_gdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlsoa_stats_xvec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlsoa_id_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlsoa_id_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mband_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pick first band\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[178], line 51\u001b[0m, in \u001b[0;36mcalc_lsoa_stats_xvec\u001b[0;34m(datasets, lsoa_gdf, out_file, lsoa_id_col, band_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(combined\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# aggregate per LSOA\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m lsoa_stats \u001b[38;5;241m=\u001b[39m \u001b[43mcombined\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlsoa_id_col\u001b[49m\u001b[43m)\u001b[49m[stats_list]\u001b[38;5;241m.\u001b[39magg(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# merge back with original polygons\u001b[39;00m\n\u001b[1;32m     54\u001b[0m lsoa_gdf_with_stats \u001b[38;5;241m=\u001b[39m lsoa_gdf\u001b[38;5;241m.\u001b[39mmerge(lsoa_stats, on\u001b[38;5;241m=\u001b[39mlsoa_id_col, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/frame.py:9183\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   9180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   9181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 9183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   9184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9186\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9189\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9193\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1329\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1329\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1332\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1334\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1337\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[1;32m   1340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/groupby/grouper.py:1043\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m   1041\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1043\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1045\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'LSOA21CD'"
     ]
    }
   ],
   "source": [
    "lsoa_stats = calc_lsoa_stats_xvec(\n",
    "    datasets=datasets,\n",
    "    lsoa_gdf=lsoa_gdf,\n",
    "    out_file=lsoa_stats_xvec,\n",
    "    lsoa_id_col=lsoa_id_col,\n",
    "    band_index=0  # pick first band\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0fd80e49-767c-45dd-bae8-600eedd2a492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data variables:\n",
      "    band_data  (band, y, x) float32 8MB ...\n",
      "Index(['band', 'spatial_ref', 'band_data'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_112/885359602.py:6: UserWarning: No active geometry column to be set. The resulting object will be a pandas.DataFrame with geopandas.GeometryArray(s) containing geometry and CRS information. Use `.set_geometry()` to set an active geometry and upcast to the geopandas.GeoDataFrame manually.\n",
      "  gdf_grid = da.xvec.to_geodataframe()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>band</th>\n",
       "      <th>spatial_ref</th>\n",
       "      <th>band_data</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">579990.0</th>\n",
       "      <th>420010.0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56.213795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420030.0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56.655174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420050.0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56.413792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420070.0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56.668964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420090.0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57.275864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   band  spatial_ref  band_data\n",
       "y        x                                     \n",
       "579990.0 420010.0     1            0  56.213795\n",
       "         420030.0     1            0  56.655174\n",
       "         420050.0     1            0  56.413792\n",
       "         420070.0     1            0  56.668964\n",
       "         420090.0     1            0  57.275864"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "\"\"\"\n",
    "# extract dataset\n",
    "ds = datasets[0]\n",
    "print(ds.data_vars)\n",
    "da = ds[\"band_data\"].isel(band=0)\n",
    "#convert to gdf\n",
    "gdf_grid = da.xvec.to_geodataframe()\n",
    "\n",
    "print(gdf_grid.columns)\n",
    "\n",
    "gdf_grid.head()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82abf97-b271-4107-832f-b91f3465a6af",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "- newer versions work directly with xarray Datasets (not even Arrays), which is good\n",
    "- might conflict with the current container. Shouldn't be installed through `pip` (this worked: `conda install xvec -c conda-forge`).\n",
    "`xvec` conflicts with `xarray>=2025.1.0`:\n",
    "> cannot import name 'AlignmentError' from 'xarray' (/opt/conda/lib/python3.12/site-packages/xarray/__init__.py)\n",
    "\n",
    "Temporarily fixed as a monkey patch in imports.\n",
    "\n",
    "-`xvec.zonal_stats` is using `exactextract` under the hood, but at the same time cannot aggregate zonal stats for each LSOA across multiple rasters - you need to do it yourself\n",
    "- this method converts too much (xarray/geodataframe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f75059",
   "metadata": {},
   "source": [
    "#### LSOA in tiles Reference index (tile -> dataset)\n",
    "\n",
    "The issue is that our xarray Datasets are tiled, while many LSOA boundaries intersect the tile boundaries. To tackle this issue, we can:\n",
    "- iterate over each tile, intersect it with the LSOAs and ...\n",
    "- create a mapping between tiled and contained LSOA (reference table). Each pixel can have more than one LSOA reference, and each LSOA can have more tile references.\n",
    "- create a mosaic first and run LSOA calculation for the entire UK. This will probably cost much resources for Dask.\n",
    "\n",
    "The goal is to avoid any repeated searches to find out which LSOAs are contained within each tile.\n",
    "In this case we create a dictionary, where each tile contains all LSOAs which do intersect that tile, or index each value by the combined index from the dataset and tile ID.\n",
    "\n",
    "Two ways of working with the dictionary (mapping):\n",
    "- if working with Dataset: rasterise tile polygons\n",
    "- if working with Dataframe:\n",
    "\n",
    "What we can do:\n",
    "- translate text tile index into integer id\n",
    "- iterate over tiles (for _,row in tiles.bounds.iterrows())\n",
    "- create a unique index for each pixel with its own index + tile id\n",
    "- for each LSOA find pixels which contain its tile id\n",
    "- calculate `exact_extract` for each LSOA\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bfa380",
   "metadata": {},
   "source": [
    "#### 4. Parquet - statistics\n",
    "- export as parquet\n",
    "- transform xarray Datasets to dataframes\n",
    "- read parquet\n",
    "- perform a spatial join between parquet points (pixel values) and LSOA features, using `dask_geopandas`\n",
    "- calculate the mean value per LSOA feature, **optionally** weighting by:\n",
    "    - number of pixel values in LSOA\n",
    "    - another dimension ('pixel_count') - how many acquisitions were gathered from satellite collections\n",
    "\n",
    "TODO:\n",
    "- Convert many tiles to parquet \n",
    "- Create unique index with x,y of each pixel (now - record)\n",
    "- Spatial join between LSOA id and unique ID of each pixel in tile -> New unique IDx\n",
    "\n",
    "Dask - geospatial library?\n",
    "`dask-geopandas`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
